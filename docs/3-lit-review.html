<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>My Final College Paper</title>
  <meta name="description" content="My Final College Paper">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="My Final College Paper" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="My Final College Paper" />
  
  
  

<meta name="author" content="Huijia Yu">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="2-intro.html">
<link rel="next" href="4-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="1-abstract.html"><a href="1-abstract.html"><i class="fa fa-check"></i><b>1</b> Abstract</a></li>
<li class="chapter" data-level="2" data-path="2-intro.html"><a href="2-intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="3-lit-review.html"><a href="3-lit-review.html"><i class="fa fa-check"></i><b>3</b> Literature Review</a></li>
<li class="chapter" data-level="4" data-path="4-models.html"><a href="4-models.html"><i class="fa fa-check"></i><b>4</b> Models</a></li>
<li class="chapter" data-level="5" data-path="5-simulation-study.html"><a href="5-simulation-study.html"><i class="fa fa-check"></i><b>5</b> Simulation Study</a><ul>
<li class="chapter" data-level="5.1" data-path="5-simulation-study.html"><a href="5-simulation-study.html#normal-example"><i class="fa fa-check"></i><b>5.1</b> Normal Example</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-simulation-study.html"><a href="5-simulation-study.html#data-generation"><i class="fa fa-check"></i><b>5.1.1</b> Data Generation</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-simulation-study.html"><a href="5-simulation-study.html#conditional-likelihood"><i class="fa fa-check"></i><b>5.1.2</b> Conditional Likelihood</a></li>
<li class="chapter" data-level="5.1.3" data-path="5-simulation-study.html"><a href="5-simulation-study.html#posterior-distribution"><i class="fa fa-check"></i><b>5.1.3</b> Posterior Distribution</a></li>
<li class="chapter" data-level="5.1.4" data-path="5-simulation-study.html"><a href="5-simulation-study.html#results"><i class="fa fa-check"></i><b>5.1.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-simulation-study.html"><a href="5-simulation-study.html#double-exponential-simulation-with-adjusted-p-values"><i class="fa fa-check"></i><b>5.2</b> Double Exponential Simulation with Adjusted P-Values</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-application.html"><a href="6-application.html"><i class="fa fa-check"></i><b>6</b> Application</a><ul>
<li class="chapter" data-level="6.1" data-path="6-application.html"><a href="6-application.html#genome-study"><i class="fa fa-check"></i><b>6.1</b> Genome Study</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-discussion.html"><a href="7-discussion.html"><i class="fa fa-check"></i><b>7</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Final College Paper</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lit-review" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Literature Review</h1>
<p>P-values have been the reason behind lack of reproducibility in scientific discoveries, causing concern and leading to proposals of new ways to define significance. Benjamin et. al have shown that the Bayes factor equivalents for commonly used p-values only correspond to “weak” evidence in the Bayes factor characterization. <span class="citation">(Benjamin et al., 2017)</span> They suggest reducing the p-value threshold in studies with less power, but acknowledge that hypothesis testing with thresholding is still an issue. Another approach is suggested by Selke et al , who propose two calibrations of the p-value: as the lower bound of the Bayes factor under any alternative hypothesis, and as a posterior probability of the type 1 error in a Bayesian framework <span class="citation">(Sellke, Bayarri, &amp; Berger, 2001)</span>.</p>
<p>This problem has become a major issue in replicated studies, an effect known as the “winner’s curse” <span class="citation">(Zöllner &amp; Pritchard, 2007)</span> or the Beavis effect <span class="citation">(S. Xu, 2003)</span>. Zollner and Pritchard first define this in the context of genome-wide association scans (GWAS), which use stringent thresholds for significance, resulting in inflated effect sizes after selection, especially since these are calculated with the same data. Thus, replication studies underestimate the sample size necessary and do not have enough power to detect an effect. Zollner and Pritchard suggest a conditional-likelihood based method to address this issue. They propose a computational algorithm to maximize over the the likelihood of the parameters conditional on the significance association at level <span class="math inline">\(\alpha\)</span>, which results in less biased coefficient estimates (albeit with larger variance) and sample size estimates centered at the true value.<span class="citation">(Zöllner &amp; Pritchard, 2007)</span></p>
<p>Zhong and Prentice also propose a similar method, but use a different parametrization and an asymptotic approximation instead of a computational one to find the estimators, which is more computationally efficient <span class="citation">(Zhong &amp; Prentice, 2008)</span>. Ghosh et al. also define an approximate conditional likelihood, and propose two more estimators (other than the MLE): the mean of the (normalized) conditional likelihood, which can be interpreted as a posterior mean of the parameters under a flat prior, and a “compromise” estimator which is the average of the mean and MLE <span class="citation">(Ghosh, Zou, &amp; Wright, 2008)</span>. The combination estimator proves to have the most stable MSE accross the range of true values for the parameters. Their approach only requires summary statistics, so they further apply it to published datasets. The results are similar for the three conditional likelihood approaches, which have been applied to other studies such as Palmer and Peter <citation>.</p>
<p>Another method proposed to create bias-reduced estimates uses bootstrap re-sampling to correct for both the thresholding effect and the ranking effect, which is not addressed in the conditional likelihood methods because of the difficulty of specifying joint likelihoods for correlated variables <span class="citation">(Sun et al., 2011)</span>. By using a sample-split approach, the detection and estimation datasets can be virtually independent. This is repeated multiple times in order to reduce variance in the results. The main drawback of this approach is its computational intensity.</p>
<p>Several authors have also proposed shrinkage-based methods in the effect detection step. Bacanu and Kendler use a soft threshold method to scale statistics such that their sum of squares do not overestimate the true mean and then find “suggestive” signals in a GWAS context by setting a threshold. This method does not address the winner’s curse directly, but provides a subset of the genome which can be futher analyzed or used in future studies <span class="citation">(Bacanu &amp; Kendler, 2013)</span>. Bigdelli et al. propose shrinking coefficient estimates by drawing a comparison between “winner’s curse adjustments” for effect sizes and multiple testing approaches for p-values, since both are used on the tail of their respective distributions. Their method transforms False Discovery Rate (FDR) adjusted p-values into the corresponding Z-score and uses that as the estimator.<span class="citation">(Bigdeli et al., 2016)</span> Both Bigdelli and Bacanu assume the data is normally distributed. Storey and Tibshirani <citation>, on the other hand, propose to adjust the value used for significance testing rather than the coefficients, choosing the FDR value as an alternative to the p-value.</p>
<p>Multiple Bayesian methods have also been proposed: Xu et al use a Bayesian approach to a logistic regression, selecting a spike and slab prior for the mean and an inverse gamma prior for the variance. <span class="citation">(L. Xu, Craiu, &amp; Sun, 2011)</span> A beta prior for the proportion of each component in the prior, and the hyperparameters were estimated empirically. They also propose a Bayesian Model Average approach, which they recommend for instances with little prior information. Their results show that the Bayesian models had smaller variance than conditional likelihood methods, but still do not address the “ranking effect” from Sun <span class="citation">(Sun et al., 2011)</span>, or implement a fully Bayesian approach because of the dependence on the threshold <span class="math inline">\(\alpha\)</span>.</p>
<p>Ferguson et al propose an Empirical Bayes approach, which estimate the prior density distribution with the data <span class="citation">(Ferguson, Cho, Yang, &amp; Zhao, 2013)</span>. This is a nonparametric estimate, but still depends on other specifications such as the number of bins, type of splines, etc. Using the empirical prior, the posterior is then calculated, from which the estimate and pseudo-Bayesian credible intervals are derived by considering the 5% and 95% points. This method resulted in better estimates in the higher density regions, but performed worse than conditional likelihood methods on the tails. Thus, the authors propose a combined method, which calculates both the empirical Bayes and the conditional likelihood confidence intervals, and picks the shortest one. One possible problem with this approach is the use of non-HPD intervals, which could change the tail behavior.</p>
<p>Jiang and Yu apply the Bayesian framework to power calculations specifically, defining “Bayesian power” as the marginal probability of finding significance in a replicated study given the original and the data. They also use a spike and slab prior, but estimate the hyperparameters empirically. The resulting power estimators are improved, but lead to downwards bias in the effect size.<span class="citation">(Jiang &amp; Yu, 2016)</span></p>
<!--
how do I cite things properly????
-->

</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
