# Models 

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(knitr)
library(ggplot2)
library(reshape2)
library(ggthemes)

```
We propose three different Bayesian approaches: 

1. A fully Bayesian mixed effects hierarchical model that can jointly perform significance testing and effect estimation. By combining the testing and estimate steps, we can overcome the winner's curse and account for the uncertainty that arises when selecting an SNP.

2. A conditional likelihood model that can take into account the probability of finding a significant result in the discovery sites when estimating effect size.

3. A bayes factor based model that uses the bayes factor from the discovery sites (which is more reliable than the p-value, as discussed previously) to quantify the uncertainty of the significant result.

While the first approach is truly Bayesian and requires all the data, the second and third can be used as long as the sufficient statistics (MLE, SE, p-value, $\alpha$) are available. 


## Fully Bayesian Model

Let $\delta_a(x)$ be the Dirac delta function: $\delta_a(x) = 1$ for $x = a$ and $\delta_a(x)=0$ otherwise. The test for significance is  $H_0: \mu = 0$,   $H_1: \mu \neq 0$, where $\mu$ is the mean effect size. Then, $P( \mu|H_0) = \delta_0 ( \mu )$,  and $P( \mu|H_1) = N(0,1)$ or some other diffuse prior. We can define a hyperparameter $\xi$ such that $P(H_1) = \xi$. This gives rise to a latent variable $\iota$ drawn from a bernoulli($\xi$), which is then used to parametrize the distribution of $\mu$.  If $\iota= 0$, $\mu=0$. 

```{r}
cond.likelihood<- function(ybar, mu, SE, q=1.96){
  dnorm(ybar, mu, SE)/
    (pnorm(-q*SE, mu, SE) +
       1-pnorm(q*SE, mu, SE))
}

p = 0.00325
LOR = log(1.65)
q = -qnorm(p/2)
# 1.21-2.25
SE =  (log(2.25 ) - LOR)/1.96
#exp(LOR + c(-1, 1)*1.96*SE)
BF = 1/(-exp(1)*p*log(p))
mu <- seq(-.2,1.25,.01)

ggplot(data = data.frame(maxy = dnorm(.4, .4,.2)/.6, x = mu, y = dnorm(mu, .4,.2), xl=0, xu=0,yl=0,yu=.4))+
  geom_line(aes(x,y/maxy))+geom_segment(aes(x=xl,y=yl,xend=xu,yend=yu))+
  labs(title= "Mixture Model with Point Mass at 0",x=expression(mu),y="density")+
  theme_minimal() + scale_colour_few()
```


For a hierarchical framework, site means $\beta_{j}|\iota=1 \sim N(\mu, \sigma^2)$, and $\beta_{j}|\iota = 0 = 0$. In this case the prior for  $\mu$ is a mixture of a point mass at zero and a Cauchy(0,1). The prior for $\sigma$ was a truncated Cauchy(0,1), with support only on the positive real line. This choice of priors is based on simulation results.  The prior for $\xi$, the probability of the alternative, was a Beta(.5,.5), which has a U-shape so that it favors 0 or 1 more heavily than the values between them. 

The complete model is as follows:

$$\beta_{j}|\iota = 1 \sim \textsf{N}(\mu, \sigma^{2}) \\
\mu|\iota=1\sim \textsf{Cauchy}(0,0.1)\\
\mu, \beta_{j}|\iota = 0  =0\\
\sigma\sim \textsf{Cauchy}(0,1), \sigma\geq 0\\
\iota \sim \textsf{Bernoulli}(\xi)\\
\xi \sim \textsf{Beta}(1/2, 1/2)$$


There is no difference between discovery and validation sites in the Bayesian framework. Even considering them separately, one could consider the posterior distributions of the parameters given only discovery site data as the priors given the validation data, which would result in exactly the same results. 

## Conditional Likelihood

In this case, the results from the discovery sites are used as a prior for the validation data analysis, which is why only the sufficient statistics are needed.

Given the discovery sites' MLE and SE, we can use the CLT and definition of MLE to state that $MLE_i \sim N(\beta_i, SE_i)$. Let $B$ indicate that the data is significant at the level $\alpha$. The conditional likelihood $L(\mu | B) = \frac{P(Y| \mu)P(B| Y,\mu)}{P(B|\mu)} =  \frac{P(Y| \mu)}{\int_{\textsf{significant Y}} P(t| \mu) dt }$. Conditioning on finding a significant estimate, $P(MLE_i | B) = \frac{\phi(MLE_i, \beta_i, SE_i)}{\Phi(-q_i, \beta_i, SE_i)+1-\Phi(q_i, \beta_i, SE_i)}$, where $\phi(x, \beta_i, \sigma)$ is the pdf of a normal distribution with mean $\beta_i$ and variance $\sigma^2$, and $\Phi(x, \beta_i, \sigma)$ is the cdf of the same distribution. The value of $q_i$ is $\Phi^{-1}(1-\frac{\alpha}{2}, 0 ,SE_i)$, where $\alpha$ is the power of the test (i.e. p-values that are smaller than $\alpha$ are considered significant). This is cutoff for an MLE value to be considered significant. Let the conditional likelihood of $MLE_i$  be denoted as $\textsf{CL}(\beta_i,SE_i, q_i)$.


```{r}
CLdata<-data.frame(mu, cond.likelihood(LOR, mu, SE, q = -qnorm(0.005/2)), 
                   cond.likelihood(LOR, mu, SE, q = -qnorm(0.05/2)),
                   cond.likelihood(LOR, mu, SE, q = -qnorm(0.01/2)),
                   dnorm(LOR, mu, SE))
colnames(CLdata)<- c("mu", "CL.005","CL.05","CL.01","uncond")
melted <- melt(CLdata, id.vars=c("mu"))
ggplot(melted, aes(mu, value, color = variable)) + geom_line(aes(group=variable)) +
  labs(title = "Conditional vs. Unconditional Likelihood", 
       x = expression(mu), y = "Likelihood")+  theme_minimal()+ 
  theme(legend.justification=c(1,1), legend.position=c(1,1)) +
  scale_colour_few(name="", labels=c(expression(paste(alpha," = .005")), 
                                     expression(paste(alpha," = .05")), 
                                     expression(paste(alpha," = .01")),
                                     "unconditional"))


```

We can see that as $\alpha$ decreases (i.e. the tests are more strict), the likelihood becomes more skewed towards 0.

In the hierarchical setting, we used the random effect conditional likelihood model as a "prior" for $\beta_{ j}, j\in \text{discovery}$, and then use this as the prior $P(\beta | \text{discovery})$ for the model with the validation data.

The updated model is:

$$\beta_{j} \sim \textsf{N}(\mu, \sigma^{2p53}) , j \in \text{validation}\\
MLE_{j} \sim \textsf{CL}(\beta_{j},SE_{j}, q_j) , j \in \text{discovery}\\
\sigma\sim \textsf{Cauchy}(0,1), \sigma\geq 0$$

Note that the selection uncertainty is somewhat accounted for through the conditional likelihood, but there is no measure of this uncertainty. By using the discovery MLEs, we are already assuming that there is a nonzero effect.

> should I go into more detail about this assumption and how conditioning sort of accounts for it

## Bayes Factor Model

The discovery data can be used not only in estimating the distribution of the size of a preestablished effect ($\mu$), but in estimating the distribution of the probability of the effect itself ($\xi = P(H_1)$). To make this model easily generalizable, we use the upper bound on the Bayes Factor $BF = \frac{L(\bar Y | H_1)}{L(\bar Y | H_0)} \leq \frac{1}{-e p log(p)}$, where $p$ is the p-value from the discovery data [@sellke2001calibration]. This is a "best-case scenario" of how much evidence there is from data given a particular p-value. Since this value is fixed given the discovery data, we can then consider the "posterior"" probability of true association $\xi$ given the discovery p-value as a transformation of $\xi$, which is parametrized with prior Beta(.5,.5). Let $o$ be the prior odds $\frac{1-\xi}{\xi}$. The transformation $\xi' = \frac{P(H_1)*L(Y|H_1)}{P(H_0)*L(Y|H_0)+P(H_1)*L(Y|H_1)} = \frac{o*BF}{1+o*BF}$. Then $\xi'$ can be used in the overall model with the validation data.

```{r}
pind.dens<-function(post.ind,p){
  BF<- 1/(-exp(1)*p*log(p)) 
  prior.odds<-post.ind/(1-post.ind)/BF
  pind<- prior.odds/(1+prior.odds) #a/0
  #eplogp is BF h0/h1
  return(pind)
  }
postind.dens<-function(pind, p=.0035){
  prior.odds<- (pind)/(1-pind) #a/0
  BF<- 1/(-exp(1)*p*log(p)) #eplogp is BF h0/h1
  post.ind<-prior.odds*BF/(1+prior.odds*BF)
  return(post.ind)
}
pind<- seq(.001, .999,by=.001)

BFapproxdata<-data.frame(pind, postind.dens(pind, .05),postind.dens(pind, .01),
                         postind.dens(pind, .005),postind.dens(pind, 1e-5),
                   dbeta(pind,.5,.5))
colnames(BFapproxdata)<-c("prior", "p = .05", "p = .01", "p = .005", "p = 1e-5","xi")
ggplot(data=melt(BFapproxdata,id.vars = "xi"), aes(y=xi))+
  geom_line(aes(x=value, group=variable,color=variable))+
  labs(title = "Distribution of Transformed Probability of Effect\n with Bayes Factor Approximation", 
       x = expression(xi), y = "Density")+  theme_minimal()+ 
  theme(legend.justification=c(1,1), legend.position=c(1,1)) +
  scale_colour_few(name="p-value")
```

In this case, the discovery data is not used at all to estimate the effect sizes, but it will have an effect on the amount of zero-valued global effects sampled because it skews the distribution to the right. Note that for small p-values, this can be very extreme. For a GWAS p-value $p = 10^{-7}$ and $\xi \sim \textsf{Beta}(.5,.5)$ , $P( \xi' \leq 0.5) =$  $`r  signif(qbeta(pind.dens(0.5,1e-7),.5,.5),3)`$ . Due to this, we use a flatter prior: $\xi \sim \textsf{Beta}(.9,.9)$ . Then $P( \xi' \leq 0.5) =$ $`r signif(qbeta(pind.dens(0.5,1e-7),.9,.9),3)`$.

This is extremely sensitive to the choice of prior as well as to the p-value. While the skew is appropriate for this particular prior, it would not necessarily make sense with a flat or informative prior.

## Methods

Models were fit using R2jags and in the simpler cases, with original Metropolis Hastings algorithms. To specify distributions that are not part of the R2jags library, such as the conditional likelihood, we use the "ones trick", which is implement by creating artificial observations of a Bernoulli variable. Consider a prior for $\theta$ that is proportional to $\pi(\theta)$. If we set that bernoulli variable "ones" is equal to 1 with probability $\pi(\theta)$, create an observation "ones"$= 1$, and set a uniform prior for $\theta$, then we are effectively creating a "posterior" for theta that is proportional to  $\pi(\theta)$ as intended.

Each JAGS model was run with the default settings: 3 chains, 2000 iterations, and 1000 burn-in samples. JAGS model functions for the hierarchical simulations can be found in the supplement.

All computed credible intervals are HPD (highest posterior density) intervals. A 95% HPD interval is the 95% of the sampled values with the highest density. HPD intervals are guaranteed to be the shortest intervals for that scale (they are not scale-invariant), and can give more reasonable answers for multimodal distributions than quantile-based intervals because they can be disjoint.

Point estimates were calculated used the posterior median, so that these estimates would be invariant to transformations (e.g. log).
